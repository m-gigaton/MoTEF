{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO 10:55:01.3350 353135 utils.py:148] Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\u001b[0m\n",
      "\u001b[32mINFO 10:55:01.3361 353135 utils.py:160] NumExpr defaulting to 8 threads.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pickle, os, time\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nda import log\n",
    "from nda.problems import *\n",
    "from nda.optimizers import *\n",
    "from nda.optimizers.utils import generate_mixing_matrix\n",
    "from nda.experiment_utils import run_exp\n",
    "\n",
    "from BEER import BEER\n",
    "#from MoTEF import BEER_Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_bits_per_round_per_agent(config, dim):\n",
    "    if 'compressor_type' in config:\n",
    "        if config['compressor_type'] == 'random':\n",
    "            return config['compressor_param'] * 64\n",
    "        elif config['compressor_type'] == 'top':\n",
    "            return config['compressor_param'] * 64\n",
    "        elif config['compressor_type'] == 'gsgd':\n",
    "            return config['compressor_param'] * dim\n",
    "    return dim * 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_exp(results, name, logx=False, logy=False, figsize=None, dpi=None, save=False, plot_norm=False, plot_bits=True, legends=None):\n",
    "\n",
    "    max_bits = min([_[1].bits.iloc[-1] for _ in results]) * 1.1\n",
    "    max_iters = min([_[1].t.iloc[-1] for _ in results])\n",
    "\n",
    "    if plot_bits:\n",
    "        fig, axs = plt.subplots(1, 4, figsize=figsize, dpi=dpi)\n",
    "    else:\n",
    "        fig, axs = plt.subplots(1, 2, figsize=figsize, dpi=dpi)\n",
    "\n",
    "    line_styles = [color + style for style in ['-', '--', ':'] for color in ['k', 'r', 'g', 'b', 'c', 'm', 'y']]\n",
    "\n",
    "    for i in range(len(results)):\n",
    "\n",
    "        data = results[i][1]\n",
    "        style = line_styles[i]\n",
    "\n",
    "        def _plot_semilog(index, x, y, n, xlabel='', ylabel=''):\n",
    "            ax = axs[index]\n",
    "            mask = data[x].values <= n\n",
    "            ax.semilogy(\n",
    "                data[x].values[mask],\n",
    "                data[y].values[mask],\n",
    "                style\n",
    "            )\n",
    "            ax.set(xlabel=xlabel, ylabel=ylabel)\n",
    "            if logy:\n",
    "                ax.set_yscale('log')\n",
    "            if logx:\n",
    "                ax.set_xscale('log')\n",
    "\n",
    "        def _plot(index, x, y, n, xlabel='', ylabel=''):\n",
    "            ax = axs[index]\n",
    "            mask = data[x].values <= n\n",
    "            ax.semilogy(\n",
    "                data[x].values[mask],\n",
    "                data[y].values[mask],\n",
    "                style\n",
    "            )\n",
    "            ax.set(xlabel=xlabel, ylabel=ylabel)\n",
    "            if logy:\n",
    "                ax.set_yscale('log')\n",
    "            if logx:\n",
    "                ax.set_xscale('log')\n",
    "\n",
    "        if not plot_norm:\n",
    "            _plot_semilog(0, 't', 'f', max_iters, xlabel='Iterations', ylabel='Training loss')\n",
    "            if plot_bits:\n",
    "                _plot_semilog(2, 'bits', 'f', max_bits, xlabel='Bits communicated', ylabel='Training loss')\n",
    "        else:\n",
    "            _plot_semilog(0, 't', 'grad_norm', max_iters, xlabel='Iterations', ylabel='Training gradient norm')\n",
    "            if plot_bits:\n",
    "                _plot_semilog(2, 'bits', 'grad_norm', max_bits, xlabel='Bits communicated', ylabel='Training gradient norm')\n",
    "\n",
    "        _plot(1, 't', 'test_accuracy', max_iters, xlabel='Iterations', ylabel='Testing accuracy')\n",
    "        if plot_bits:\n",
    "            _plot(3, 'bits', 'test_accuracy', max_bits, xlabel='Bits communicated', ylabel='Testing accuracy')\n",
    "\n",
    "    if legends is None:\n",
    "        plt.legend([_[0] for _ in results])\n",
    "    else:\n",
    "        plt.legend(legends)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"data\", exist_ok=True)  # Creates \"data\" directory if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_exp(results, configs, name, **kwargs):\n",
    "\n",
    "    for res, config in zip(results, configs):\n",
    "        data = res[1]\n",
    "        data['t'] = data['t'].astype(int)\n",
    "        data['n_grads'] = data['n_grads'].astype(int)\n",
    "        data['bits'] = get_bits_per_round_per_agent(config, p.dim) * p.n_agent * data.comm_rounds\n",
    "\n",
    "    kwargs['results'] = results\n",
    "    with open(f\"data/{name}.pkl\", 'wb') as f:\n",
    "        pickle.dump(kwargs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonconvex logistic regression on unshuffled a9a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# n_agent = 100\n",
    "# dataset = 'a9a'\n",
    "# graph_type = 'cycle'\n",
    "\n",
    "\n",
    "# p = LogisticRegression(n_agent=n_agent, graph_type=graph_type, alpha=0.05, dataset=dataset, sort=True)\n",
    "\n",
    "# m = p.m\n",
    "# dim = p.dim\n",
    "\n",
    "# x_0 = np.random.rand(dim, n_agent)\n",
    "# W, alpha = generate_mixing_matrix(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning of BEER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_iters = 6000\n",
    "# batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = f'BEER_logistic_regression_nonconvex_{dataset}_unshuffled_algorithms_path'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extra_metrics = ['test_accuracy', 'grad_norm']\n",
    "\n",
    "# BEER_configs = []\n",
    "# for eta in [0.001, 0.01, 0.05]:\n",
    "#     for gamma in [0.1, 0.2, 0.5, 0.9]:\n",
    "#             BEER_configs.append({'eta': eta, 'compressor_param': 5, 'gamma': gamma,'compressor_type': 'gsgd'})\n",
    "\n",
    "\n",
    "\n",
    "# for _ in BEER_configs:\n",
    "#     _['extra_metrics'] = extra_metrics\n",
    "\n",
    "# configs = BEER_configs\n",
    "# exps = [BEER(p, n_iters=n_iters, batch_size=batch_size, x_0=x_0, W=W, **config) for config in BEER_configs] \n",
    "\n",
    "# begin = time.time()\n",
    "# res_BEER = run_exp(exps, max_iter=n_iters, name=name, n_gpus=4, plot=False)\n",
    "# end = time.time()\n",
    "# log.info('Total %.2fs', end - begin)\n",
    "\n",
    "\n",
    "# results = save_exp(res_BEER, configs, name, p=p, x_0=x_0, W=W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-hidden-layer NN on MNIST or ResNET8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nda.problems.resnet8 import ResNet8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO 10:55:03.8957 353135 dataset.py:31] Loading MNIST dataset from cached file\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization done\n",
      "alpha = 0.8256645490249561\n"
     ]
    }
   ],
   "source": [
    "experiment = 'nn'\n",
    "graph_type = 'cycle'\n",
    "n_agent = 10\n",
    "\n",
    "p = NN(n_agent=n_agent, graph_type=graph_type, sort=True)\n",
    "#p = ResNet8(n_agent=n_agent, graph_type=graph_type, sort=True)\n",
    "m = p.m\n",
    "dim = p.dim\n",
    "\n",
    "x_0 = np.random.randn(dim, n_agent) / 10\n",
    "\n",
    "W, alpha = generate_mixing_matrix(p)\n",
    "\n",
    "print('alpha = ' + str(alpha))\n",
    "x_0_mean = x_0.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'mnist_unshuffled__BEER_resnet8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO 10:55:06.3672 353135 BEER.py:21] gamma = 0.600\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment setup\n",
      "Launching task 0 on device 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO 10:55:13.6708 353243 utils.py:148] Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\u001b[0m\n",
      "\u001b[32mINFO 10:55:13.6710 353243 utils.py:160] NumExpr defaulting to 8 threads.\u001b[0m\n",
      "\u001b[32mINFO 10:55:16.2579 353243 utils.py:22] BEER started\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEER started\n",
      "grad_h called with w shape: (421642, 10), i: None, j: None\n",
      "wdim calling:2\n",
      "Forward-backward pass called with X shape: (6000, 785), Y shape: (6000, 10), w shape: (421642,)\n",
      "Original shape of X: (6000, 785)\n",
      "Reshaped shape of X: torch.Size([6000, 1, 28, 28])\n",
      "Gradients computed with shape: torch.Size([421642])\n",
      "Forward-backward pass called with X shape: (6000, 785), Y shape: (6000, 10), w shape: (421642,)\n",
      "Original shape of X: (6000, 785)\n",
      "Reshaped shape of X: torch.Size([6000, 1, 28, 28])\n",
      "Gradients computed with shape: torch.Size([421642])\n",
      "Forward-backward pass called with X shape: (6000, 785), Y shape: (6000, 10), w shape: (421642,)\n",
      "Original shape of X: (6000, 785)\n",
      "Reshaped shape of X: torch.Size([6000, 1, 28, 28])\n",
      "Gradients computed with shape: torch.Size([421642])\n",
      "Forward-backward pass called with X shape: (6000, 785), Y shape: (6000, 10), w shape: (421642,)\n",
      "Original shape of X: (6000, 785)\n",
      "Reshaped shape of X: torch.Size([6000, 1, 28, 28])\n",
      "Gradients computed with shape: torch.Size([421642])\n",
      "Forward-backward pass called with X shape: (6000, 785), Y shape: (6000, 10), w shape: (421642,)\n",
      "Original shape of X: (6000, 785)\n",
      "Reshaped shape of X: torch.Size([6000, 1, 28, 28])\n",
      "Gradients computed with shape: torch.Size([421642])\n",
      "Forward-backward pass called with X shape: (6000, 785), Y shape: (6000, 10), w shape: (421642,)\n",
      "Original shape of X: (6000, 785)\n",
      "Reshaped shape of X: torch.Size([6000, 1, 28, 28])\n",
      "Gradients computed with shape: torch.Size([421642])\n",
      "Forward-backward pass called with X shape: (6000, 785), Y shape: (6000, 10), w shape: (421642,)\n",
      "Original shape of X: (6000, 785)\n",
      "Reshaped shape of X: torch.Size([6000, 1, 28, 28])\n",
      "Gradients computed with shape: torch.Size([421642])\n",
      "Forward-backward pass called with X shape: (6000, 785), Y shape: (6000, 10), w shape: (421642,)\n",
      "Original shape of X: (6000, 785)\n",
      "Reshaped shape of X: torch.Size([6000, 1, 28, 28])\n",
      "Gradients computed with shape: torch.Size([421642])\n",
      "Forward-backward pass called with X shape: (6000, 785), Y shape: (6000, 10), w shape: (421642,)\n",
      "Original shape of X: (6000, 785)\n",
      "Reshaped shape of X: torch.Size([6000, 1, 28, 28])\n",
      "Gradients computed with shape: torch.Size([421642])\n",
      "Forward-backward pass called with X shape: (6000, 785), Y shape: (6000, 10), w shape: (421642,)\n",
      "Original shape of X: (6000, 785)\n",
      "Reshaped shape of X: torch.Size([6000, 1, 28, 28])\n",
      "Gradients computed with shape: torch.Size([421642])\n",
      "h called with w shape: (421642,), i: None, j: None, split: train\n",
      "Forward pass called with X shape: (60000, 785), Y shape: (60000, 10), w shape: (421642,)\n",
      "Original shape of X: (60000, 785)\n",
      "Reshaped shape of X: torch.Size([60000, 1, 28, 28])\n",
      "Final results after sorting: []\n",
      "Total 54.78s\n",
      "No results to save.\n"
     ]
    }
   ],
   "source": [
    "n_iters = 3\n",
    "batch_size = 100\n",
    "eta = 0.1\n",
    "\n",
    "extra_metrics = ['test_accuracy', 'grad_norm']\n",
    "\n",
    "# MoTEF_configs = [\n",
    "#         {'eta': eta, 'compressor_param': 20, 'gamma': 6e-1, 'lmbd':0.005, 'compressor_type': 'gsgd', 'extra_metrics': extra_metrics},\n",
    "# ]\n",
    "\n",
    "BEER_configs = [\n",
    "        {'eta': eta, 'compressor_param': 20, 'gamma': 6e-1, 'compressor_type': 'gsgd', 'extra_metrics': extra_metrics},\n",
    "]\n",
    "\n",
    "# CHOCO_SGD_configs = [\n",
    "#         {'eta': eta, 'compressor_param': 20, 'gamma': 6e-1, 'compressor_type': 'gsgd', 'extra_metrics': extra_metrics},\n",
    "# ]\n",
    "\n",
    "# for _ in CHOCO_SGD_configs + BEER_configs + MoTEF_configs:\n",
    "#     _['extra_metrics'] = extra_metrics\n",
    "\n",
    "baseline_exps = [\n",
    "        DSGD(p, eta=eta, n_iters=n_iters, batch_size=batch_size, x_0=x_0, W=W, early_stopping=False, extra_metrics=extra_metrics),\n",
    "        D2(p, eta=eta, n_iters=n_iters, batch_size=batch_size, x_0=x_0, W=W, early_stopping=False, extra_metrics=extra_metrics),\n",
    "    ]\n",
    "\n",
    "\n",
    "#configs = MoTEF_configs + BEER_configs + CHOCO_SGD_configs + len(baseline_exps) * [{}]\n",
    "configs = BEER_configs\n",
    "# exps = [MoTEF(p, n_iters=n_iters, batch_size=batch_size, x_0=x_0, W=W, early_stopping=False, **config) for config in MoTEF_configs] \\\n",
    "#         + [BEER(p, n_iters=n_iters, batch_size=batch_size, x_0=x_0, W=W, early_stopping=False, **config) for config in BEER_configs] \\\n",
    "#         + [CHOCO_SGD(p, n_iters=int(n_iters * 2), batch_size=batch_size, x_0=x_0, W=W, early_stopping=False, **config) for config in CHOCO_SGD_configs] \\\n",
    "#         + baseline_exps\n",
    "\n",
    "exps = [BEER(p, n_iters=n_iters, batch_size=batch_size, x_0=x_0, W=W, early_stopping=False, **config) for config in BEER_configs]\n",
    "\n",
    "# Adding debug statements\n",
    "print(\"Starting experiment setup\")\n",
    "\n",
    "begin = time.time()\n",
    "try:\n",
    "    res = run_exp(exps, max_iter=n_iters, name=name, n_gpus=1, plot=False, save=True)\n",
    "except Exception as e:\n",
    "    print(f\"Error running experiments: {e}\")\n",
    "    res = []\n",
    "\n",
    "end = time.time()\n",
    "print('Total %.2fs' % (end - begin))\n",
    "\n",
    "if res:\n",
    "    save_exp(res, configs, name, p=p, x_0=x_0, W=W)\n",
    "else:\n",
    "    print(\"No results to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "min() iterable argument is empty",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m _ \u001b[38;5;241m=\u001b[39m plot_exp(res, name, plot_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m4\u001b[39m), dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m, in \u001b[0;36mplot_exp\u001b[0;34m(results, name, logx, logy, figsize, dpi, save, plot_norm, plot_bits, legends)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_exp\u001b[39m(results, name, logx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, logy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, figsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, plot_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, plot_bits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, legends\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m----> 3\u001b[0m     max_bits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m([_[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mbits\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m results]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1.1\u001b[39m\n\u001b[1;32m      4\u001b[0m     max_iters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m([_[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mt\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m results])\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m plot_bits:\n",
      "\u001b[0;31mValueError\u001b[0m: min() iterable argument is empty"
     ]
    }
   ],
   "source": [
    " _ = plot_exp(res, name, plot_norm=True, figsize=(16, 4), dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
